{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "ROOT_DIR = \"./outputs\"\n",
    "CSV_NAME = \"sit_format.csv\"\n",
    "PLOTS_DIR = \"./plots\"\n",
    "\n",
    "REQUIRED_COLS = [\n",
    "    \"training_time\",\n",
    "    \"total_steps\",\n",
    "    \"test/mean_reward\",\n",
    "    \"test/median_reward\",\n",
    "    \"loss/dist_entropy\",\n",
    "]\n",
    "\n",
    "PLOTS = [\n",
    "    {\"x\": \"t\", \"y\": \"test/mean_reward\", \"xlabel\": \"Time (s)\", \"ylabel\": \"Mean reward\", \"title\": \"Test reward over time (mean)\"},\n",
    "    {\"x\": \"t\", \"y\": \"test/median_reward\", \"xlabel\": \"Time (s)\", \"ylabel\": \"Median reward\", \"title\": \"Test reward over time (median)\"},\n",
    "    {\"x\": \"steps_norm_global\", \"y\": \"test/mean_reward\", \"xlabel\": \"Training progress (%)\", \"ylabel\": \"Mean reward\", \"title\": \"Test reward vs progress (mean)\"},\n",
    "    {\"x\": \"steps_norm_global\", \"y\": \"test/median_reward\", \"xlabel\": \"Training progress (%)\", \"ylabel\": \"Median reward\", \"title\": \"Test reward vs progress (median)\"},\n",
    "    {\"x\": \"steps_norm_global\", \"y\": \"loss/dist_entropy\", \"xlabel\": \"Training progress (%)\", \"ylabel\": \"Policy entropy\", \"title\": \"Policy entropy vs progress\"},\n",
    "]\n",
    "\n",
    "ROLL_WINDOW = 10\n",
    "UNCERTAINTY_SCALE = 1.0\n",
    "BAND_ALPHA = 0.10\n",
    "STANDARD_ERROR_BANDS = False\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s | %(message)s\")\n",
    "logger = logging.getLogger(\"sit_plot\")\n",
    "\n",
    "def ensure_dirs():\n",
    "    os.makedirs(ROOT_DIR, exist_ok=True)\n",
    "    os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "def find_run_csvs(root, csv_name):\n",
    "    paths = []\n",
    "    for dirpath, _, filenames in os.walk(root):\n",
    "        if csv_name in filenames:\n",
    "            paths.append(os.path.join(dirpath, csv_name))\n",
    "    return sorted(paths)\n",
    "\n",
    "def infer_run_name(path, root):\n",
    "    rel = os.path.relpath(os.path.dirname(path), root)\n",
    "    return rel.replace(\"\\\\\", \"/\")\n",
    "\n",
    "def ensure_numeric(series, name):\n",
    "    if series is None:\n",
    "        raise ValueError(f\"Column '{name}' missing\")\n",
    "    v = pd.to_numeric(series, errors=\"raise\").astype(float).values\n",
    "    if v.size == 0 or not np.isfinite(v).any():\n",
    "        raise ValueError(f\"Column '{name}' has no finite numeric values\")\n",
    "    return v\n",
    "\n",
    "def build_time_seconds(df):\n",
    "    t = ensure_numeric(df[\"training_time\"], \"training_time\")\n",
    "    t0 = np.nanmin(t)\n",
    "    if not np.isfinite(t0):\n",
    "        raise ValueError(\"training_time min not finite\")\n",
    "    if t0 != 0:\n",
    "        t = t - t0\n",
    "    return t\n",
    "\n",
    "def normalize_time_per_run(t):\n",
    "    total = np.nanmax(t)\n",
    "    if not np.isfinite(total) or total <= 0:\n",
    "        raise ValueError(\"training_time max invalid for normalization\")\n",
    "    return np.clip(t / float(total), 0.0, np.inf)\n",
    "\n",
    "def build_steps(df):\n",
    "    steps = ensure_numeric(df[\"total_steps\"], \"total_steps\")\n",
    "    s0 = np.nanmin(steps)\n",
    "    if not np.isfinite(s0):\n",
    "        raise ValueError(\"total_steps min not finite\")\n",
    "    if s0 != 0:\n",
    "        steps = steps - s0\n",
    "    return steps\n",
    "\n",
    "def smooth_series(y):\n",
    "    s = pd.Series(y, dtype=float)\n",
    "    return s.rolling(ROLL_WINDOW, min_periods=ROLL_WINDOW).mean().values\n",
    "\n",
    "def uncertainty_series(y):\n",
    "    s = pd.Series(y, dtype=float)\n",
    "    std = s.rolling(ROLL_WINDOW, min_periods=ROLL_WINDOW).std(ddof=1)\n",
    "    if STANDARD_ERROR_BANDS:\n",
    "        se = std / np.sqrt(ROLL_WINDOW)\n",
    "        return se.values\n",
    "    return std.values\n",
    "\n",
    "def load_runs(root):\n",
    "    paths = find_run_csvs(root, CSV_NAME)\n",
    "    if not paths:\n",
    "        logger.error(f\"No CSVs named '{CSV_NAME}' found under root='{root}'\")\n",
    "        return pd.DataFrame()\n",
    "    frames = []\n",
    "    for p in paths:\n",
    "        run = infer_run_name(p, root)\n",
    "        try:\n",
    "            df = pd.read_csv(p)\n",
    "            missing = [c for c in REQUIRED_COLS if c not in df.columns]\n",
    "            if missing:\n",
    "                raise ValueError(f\"Missing required columns: {missing}\")\n",
    "            t = build_time_seconds(df)\n",
    "            tn = normalize_time_per_run(t)\n",
    "            steps = build_steps(df)\n",
    "            y_mean = ensure_numeric(df[\"test/mean_reward\"], \"test/mean_reward\")\n",
    "            y_median = ensure_numeric(df[\"test/median_reward\"], \"test/median_reward\")\n",
    "            entropy_col = ensure_numeric(df[\"loss/dist_entropy\"], \"loss/dist_entropy\")\n",
    "            sub = pd.DataFrame({\n",
    "                \"run\": run,\n",
    "                \"t\": t,\n",
    "                \"t_norm\": tn,\n",
    "                \"steps\": steps,\n",
    "                \"test/mean_reward\": y_mean,\n",
    "                \"test/median_reward\": y_median,\n",
    "                \"loss/dist_entropy\": entropy_col,\n",
    "            })\n",
    "            sub = sub.sort_values(\"t_norm\")\n",
    "            frames.append(sub)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[{run}] skipping due to error: {e}\")\n",
    "            continue\n",
    "    if not frames:\n",
    "        logger.error(\"No valid runs loaded after strict validation\")\n",
    "        return pd.DataFrame()\n",
    "    df_all = pd.concat(frames, ignore_index=True)\n",
    "    smax_global = np.nanmax(df_all[\"steps\"].values)\n",
    "    if not np.isfinite(smax_global) or smax_global <= 0:\n",
    "        logger.error(\"Global total_steps max invalid for normalization\")\n",
    "        return df_all\n",
    "    df_all[\"steps_norm_global\"] = np.clip(df_all[\"steps\"].values / float(smax_global), 0.0, 1.0)\n",
    "    return df_all\n",
    "\n",
    "def percent_formatter(ax):\n",
    "    bp = np.arange(0.0, 1.0 + 1e-9, 0.1)\n",
    "    ax.set_xticks(bp)\n",
    "    ax.set_xticklabels([f\"{int(v*100)}%\" for v in bp])\n",
    "\n",
    "def plot_runs(ax, df, runs, x, y, xlabel, ylabel, title):\n",
    "    plotted_any = False\n",
    "    for r in runs:\n",
    "        d = df[df[\"run\"] == r]\n",
    "        xv = d[x].values\n",
    "        yv = d[y].values\n",
    "        if yv.size == 0 or np.all(~np.isfinite(yv)):\n",
    "            logger.error(f\"[{r}] plot '{title}' y='{y}' invalid; strict mode skips\")\n",
    "            continue\n",
    "        ys = smooth_series(yv)\n",
    "        u = uncertainty_series(yv)\n",
    "        mask = np.isfinite(xv) & np.isfinite(ys) & np.isfinite(u)\n",
    "        xv2, ys2, u2 = xv[mask], ys[mask], u[mask]\n",
    "        if xv2.size == 0:\n",
    "            logger.error(f\"[{r}] plot '{title}' insufficient finite points after smoothing\")\n",
    "            continue\n",
    "        ax.plot(xv2, ys2, label=r, linewidth=2.0, alpha=0.95)\n",
    "        ax.fill_between(xv2, ys2 - UNCERTAINTY_SCALE * u2, ys2 + UNCERTAINTY_SCALE * u2, alpha=BAND_ALPHA, linewidth=0)\n",
    "        plotted_any = True\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    if x == \"t_norm\":\n",
    "        ax.set_xlim(0, 1.0)\n",
    "        percent_formatter(ax)\n",
    "    elif x == \"t\":\n",
    "        xmax = np.nanmax(df[\"t\"].values)\n",
    "        if np.isfinite(xmax):\n",
    "            ax.set_xlim(0, xmax)\n",
    "    elif x == \"steps_norm_global\":\n",
    "        ax.set_xlim(0, 1.0)\n",
    "        percent_formatter(ax)\n",
    "    ax.grid(True, alpha=0.35)\n",
    "    if plotted_any:\n",
    "        ax.legend(loc=\"best\", fontsize=8, framealpha=0.3)\n",
    "    else:\n",
    "        logger.error(f\"No lines plotted for '{title}'\")\n",
    "\n",
    "def safe_filename(s):\n",
    "    return \"\".join(c if c.isalnum() or c in \"-_.\" else \"_\" for c in s).lower()\n",
    "\n",
    "def save_plot(fig, name, dpi=200):\n",
    "    os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "    fname = safe_filename(name)\n",
    "    path_png = os.path.join(PLOTS_DIR, f\"{fname}.png\")\n",
    "    fig.savefig(path_png, dpi=dpi, bbox_inches=\"tight\")\n",
    "    logger.info(f\"Saved plot: {path_png}\")\n",
    "\n",
    "def main():\n",
    "    ensure_dirs()\n",
    "    try:\n",
    "        matplotlib.rcParams[\"figure.dpi\"] = 120\n",
    "        matplotlib.rcParams[\"savefig.dpi\"] = 200\n",
    "        matplotlib.rcParams[\"axes.spines.top\"] = False\n",
    "        matplotlib.rcParams[\"axes.spines.right\"] = False\n",
    "        matplotlib.rcParams[\"grid.linestyle\"] = \"--\"\n",
    "        matplotlib.rcParams[\"legend.frameon\"] = True\n",
    "        try:\n",
    "            plt.rcParams[\"text.usetex\"] = False\n",
    "        except Exception:\n",
    "            pass\n",
    "    except Exception:\n",
    "        pass\n",
    "    df = load_runs(ROOT_DIR)\n",
    "    if df.empty:\n",
    "        print(f\"No {CSV_NAME} files with required columns found under: {ROOT_DIR}\")\n",
    "        return\n",
    "    runs = df[\"run\"].unique().tolist()\n",
    "    if not runs:\n",
    "        print(f\"No valid runs after strict validation under: {ROOT_DIR}\")\n",
    "        return\n",
    "    rows, cols = 3, 2\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(14, 9.5), constrained_layout=True)\n",
    "    axes = axes.flatten()\n",
    "    for i, cfg in enumerate(PLOTS):\n",
    "        plot_runs(axes[i], df, runs, **cfg)\n",
    "    for j in range(len(PLOTS), rows * cols):\n",
    "        fig.delaxes(axes[j])\n",
    "    save_plot(fig, \"Summary grid\")\n",
    "    for i, cfg in enumerate(PLOTS[:len(PLOTS)]):\n",
    "        f, ax = plt.subplots(1, 1, figsize=(7, 4.8), constrained_layout=True)\n",
    "        plot_runs(ax, df, runs, **cfg)\n",
    "        save_plot(f, f\"{cfg['title']}\")\n",
    "        plt.show(block=False)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "bfff4503765adfb6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, LogNorm, SymLogNorm\n",
    "\n",
    "ROOT_DIR = \"./outputs\"\n",
    "CSV_NAME = \"sit_format.csv\"\n",
    "\n",
    "Y_MEAN = \"test/mean_episode_reward\"\n",
    "Y_MEDIAN = \"test/median_episode_reward\"\n",
    "Y_MEAN_ALIASES = [Y_MEAN, \"test/mean_reward\"]\n",
    "Y_MEDIAN_ALIASES = [Y_MEDIAN, \"test/median_reward\"]\n",
    "\n",
    "LAST_N = 50\n",
    "WINSOR_Q = 0.10\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s | %(message)s\")\n",
    "logger = logging.getLogger(\"sit_matrix_nb\")\n",
    "\n",
    "def find_run_csvs(root, csv_name):\n",
    "    paths = []\n",
    "    for dirpath, _, filenames in os.walk(root):\n",
    "        if csv_name in filenames:\n",
    "            paths.append(os.path.join(dirpath, csv_name))\n",
    "    paths = sorted(paths)\n",
    "    if not paths:\n",
    "        logger.warning(f\"No CSVs named '{csv_name}' found under root='{root}'\")\n",
    "    return paths\n",
    "\n",
    "def infer_run_name(path, root):\n",
    "    rel = os.path.relpath(os.path.dirname(path), root)\n",
    "    return rel.replace(\"\\\\\", \"/\")\n",
    "\n",
    "def parse_p_m_from_run(run_name):\n",
    "    p_match = re.search(r\"p([+-]?\\d*\\.?\\d+(?:[eE][+-]?\\d+)?)\", run_name)\n",
    "    m_match = re.search(r\"m([+-]?\\d*\\.?\\d+(?:[eE][+-]?\\d+)?)\", run_name)\n",
    "    p = float(p_match.group(1)) if p_match else np.nan\n",
    "    m = float(m_match.group(1)) if m_match else np.nan\n",
    "    if not np.isfinite(p) or not np.isfinite(m):\n",
    "        logger.warning(f\"[{run_name}] could not parse p/m from run name; got p={p}, m={m}\")\n",
    "    return p, m\n",
    "\n",
    "def get_first_present(df, names):\n",
    "    for n in names:\n",
    "        if n in df.columns:\n",
    "            return n\n",
    "    return None\n",
    "\n",
    "def _nan_masked_tail(series, n):\n",
    "    x = pd.to_numeric(pd.Series(series), errors=\"coerce\").dropna().values\n",
    "    if x.size == 0:\n",
    "        return x\n",
    "    n_eff = min(n, x.size) if n is not None and n > 0 else x.size\n",
    "    return x[-n_eff:]\n",
    "\n",
    "def winsorized_mean_lastN(series, n, q):\n",
    "    x = _nan_masked_tail(series, n)\n",
    "    if x.size == 0:\n",
    "        return np.nan\n",
    "    if x.size < 3:\n",
    "        return float(np.mean(x))\n",
    "    q = max(0.0, min(0.5, q))\n",
    "    if q == 0.0:\n",
    "        return float(np.mean(x))\n",
    "    lo, hi = np.quantile(x, [q, 1 - q])\n",
    "    xw = np.clip(x, lo, hi)\n",
    "    return float(np.mean(xw))\n",
    "\n",
    "def load_last_metrics(root):\n",
    "    paths = find_run_csvs(root, CSV_NAME)\n",
    "    rows = []\n",
    "    for pth in paths:\n",
    "        run = infer_run_name(pth, root)\n",
    "        try:\n",
    "            df = pd.read_csv(pth)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[{run}] failed to read CSV '{pth}': {e}\")\n",
    "            continue\n",
    "        y_mean_col = get_first_present(df, Y_MEAN_ALIASES)\n",
    "        y_median_col = get_first_present(df, Y_MEDIAN_ALIASES)\n",
    "        if y_mean_col is None and y_median_col is None:\n",
    "            logger.warning(f\"[{run}] missing target columns; looked for {Y_MEAN_ALIASES} and {Y_MEDIAN_ALIASES}; skipping\")\n",
    "            continue\n",
    "        mean_series = df.get(y_mean_col, pd.Series(dtype=float))\n",
    "        median_series = df.get(y_median_col, pd.Series(dtype=float))\n",
    "        mean_est = winsorized_mean_lastN(mean_series, LAST_N, WINSOR_Q) if y_mean_col is not None else np.nan\n",
    "        median_est = winsorized_mean_lastN(median_series, LAST_N, WINSOR_Q) if y_median_col is not None else np.nan\n",
    "        if np.isnan(mean_est) and np.isnan(median_est):\n",
    "            logger.warning(f\"[{run}] last-N robust estimators returned NaN for both mean/median; skipping\")\n",
    "            continue\n",
    "        p_val, m_val = parse_p_m_from_run(run)\n",
    "        rows.append({\n",
    "            \"run\": run,\n",
    "            \"p\": p_val,\n",
    "            \"m\": m_val,\n",
    "            \"mean_lastN_winsor\": mean_est,\n",
    "            \"median_lastN_winsor\": median_est,\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "def build_matrices(rows):\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        return np.array([]), np.array([]), np.array([[]]), np.array([[]]), pd.DataFrame(columns=[\"p\",\"m\",\"mean_lastN_winsor\",\"median_lastN_winsor\"])\n",
    "    P_vals = np.sort(df[\"p\"].dropna().unique())\n",
    "    M_vals = np.sort(df[\"m\"].dropna().unique())\n",
    "    mean_matrix = np.full((len(P_vals), len(M_vals)), np.nan, dtype=float)\n",
    "    median_matrix = np.full((len(P_vals), len(M_vals)), np.nan, dtype=float)\n",
    "    grouped = df.groupby([\"p\", \"m\"], dropna=True).agg({\n",
    "        \"mean_lastN_winsor\": \"mean\",\n",
    "        \"median_lastN_winsor\": \"mean\"\n",
    "    }).reset_index()\n",
    "    p_index = {p: i for i, p in enumerate(P_vals)}\n",
    "    m_index = {m: j for j, m in enumerate(M_vals)}\n",
    "    for _, row in grouped.iterrows():\n",
    "        p, m = row[\"p\"], row[\"m\"]\n",
    "        if p in p_index and m in m_index:\n",
    "            i, j = p_index[p], m_index[m]\n",
    "            mean_matrix[i, j] = row[\"mean_lastN_winsor\"]\n",
    "            median_matrix[i, j] = row[\"median_lastN_winsor\"]\n",
    "    tidy = pd.DataFrame({\n",
    "        \"p\": np.repeat(P_vals, len(M_vals)),\n",
    "        \"m\": np.tile(M_vals, len(P_vals)),\n",
    "        \"mean_lastN_winsor\": mean_matrix.reshape(-1),\n",
    "        \"median_lastN_winsor\": median_matrix.reshape(-1),\n",
    "    })\n",
    "    return P_vals, M_vals, mean_matrix, median_matrix, tidy\n",
    "\n",
    "def make_green_good_red_bad_cmap():\n",
    "    colors = [\n",
    "        (0.0, \"#d73027\"),\n",
    "        (0.5, \"#fdae61\"),\n",
    "        (0.75, \"#a6d96a\"),\n",
    "        (1.0, \"#1a9850\"),\n",
    "    ]\n",
    "    return LinearSegmentedColormap.from_list(\"red_yellow_green\", colors)\n",
    "\n",
    "rows = load_last_metrics(ROOT_DIR)\n",
    "if not rows:\n",
    "    print(f\"No valid runs found to build matrices from: {ROOT_DIR}\")\n",
    "else:\n",
    "    P_vals, M_vals, mean_matrix, median_matrix, tidy = build_matrices(rows)\n",
    "\n",
    "    try:\n",
    "        display(pd.DataFrame(rows))\n",
    "        display(tidy)\n",
    "    except NameError:\n",
    "        print(pd.DataFrame(rows).head())\n",
    "        print(tidy.head())\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5), constrained_layout=True)\n",
    "    cmap = make_green_good_red_bad_cmap()\n",
    "\n",
    "    def imshow_with_axes(ax, matrix, P_vals, M_vals, title):\n",
    "        finite_vals = matrix[np.isfinite(matrix)]\n",
    "        if finite_vals.size == 0:\n",
    "            vmin, vmax = 0.0, 1.0\n",
    "        else:\n",
    "            vmin, vmax = np.nanmin(finite_vals), np.nanmax(finite_vals)\n",
    "            if np.isclose(vmin, vmax):\n",
    "                delta = 1.0 if vmax == 0 else abs(vmax) * 0.1\n",
    "                vmin, vmax = vmax - delta, vmax + delta\n",
    "        if finite_vals.size == 0:\n",
    "            norm = LogNorm(vmin=1e-6, vmax=1.0)\n",
    "        elif np.all(finite_vals > 0):\n",
    "            eps = np.nextafter(0, 1)\n",
    "            norm = LogNorm(vmin=max(vmin, eps), vmax=vmax)\n",
    "        else:\n",
    "            linthresh = max(1e-6, 0.01 * max(1e-9, (vmax - vmin)))\n",
    "            norm = SymLogNorm(linthresh=linthresh, vmin=vmin, vmax=vmax)\n",
    "        im = ax.imshow(matrix, aspect=\"auto\", origin=\"lower\", cmap=cmap, norm=norm)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"m\")\n",
    "        ax.set_ylabel(\"p\")\n",
    "        ax.set_xticks(range(len(M_vals)))\n",
    "        ax.set_yticks(range(len(P_vals)))\n",
    "        ax.set_xticklabels([f\"{m:g}\" for m in M_vals], rotation=45, ha=\"right\")\n",
    "        ax.set_yticklabels([f\"{p:g}\" for p in P_vals])\n",
    "        im.cmap.set_bad(color=\"#bdbdbd\")\n",
    "        im.set_data(np.ma.masked_invalid(matrix))\n",
    "        cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.ax.set_ylabel(\"reward (log-scaled)\", rotation=270, labelpad=12)\n",
    "\n",
    "    imshow_with_axes(axes[0], mean_matrix, P_vals, M_vals, f\"Mean reward (winsorized last {LAST_N}) green=good red=bad\")\n",
    "    imshow_with_axes(axes[1], median_matrix, P_vals, M_vals, f\"Median reward (winsorized last {LAST_N}) green=good red=bad\")\n",
    "\n",
    "    plt.show()\n"
   ],
   "id": "cfbd5685c7440b96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, LogNorm, SymLogNorm\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "ROOT_DIR = \"./outputs\"\n",
    "CSV_NAME = \"sit_format.csv\"\n",
    "PLOTS_DIR = \"./plots\"\n",
    "PNG_NAME = \"mean_reward_matrix.png\"\n",
    "\n",
    "Y_MEAN = \"test/mean_episode_reward\"\n",
    "Y_MEAN_ALIASES = [Y_MEAN, \"test/mean_reward\"]\n",
    "\n",
    "def find_run_csvs(root: str, csv_name: str) -> List[str]:\n",
    "    paths = []\n",
    "    for dirpath, _, filenames in os.walk(root):\n",
    "        if csv_name in filenames:\n",
    "            paths.append(os.path.join(dirpath, csv_name))\n",
    "    paths = sorted(paths)\n",
    "    return paths\n",
    "\n",
    "def infer_run_name(path: str, root: str) -> str:\n",
    "    rel = os.path.relpath(os.path.dirname(path), root)\n",
    "    return rel.replace(\"\\\\\", \"/\")\n",
    "\n",
    "def parse_p_m_from_run(run_name: str) -> Tuple[float, float]:\n",
    "    p_match = re.search(r\"p([+-]?\\d*\\.?\\d+(?:[eE][+-]?\\d+)?)\", run_name)\n",
    "    m_match = re.search(r\"m([+-]?\\d*\\.?\\d+(?:[eE][+-]?\\d+)?)\", run_name)\n",
    "    p = float(p_match.group(1)) if p_match else np.nan\n",
    "    m = float(m_match.group(1)) if m_match else np.nan\n",
    "    return p, m\n",
    "\n",
    "def get_first_present(df: pd.DataFrame, names: List[str]) -> str | None:\n",
    "    for n in names:\n",
    "        if n in df.columns:\n",
    "            return n\n",
    "    return None\n",
    "\n",
    "def mean_max(series: pd.Series | List[Any]) -> float:\n",
    "    x = pd.to_numeric(pd.Series(series), errors=\"coerce\").dropna().values\n",
    "    if x.size == 0:\n",
    "        return np.nan\n",
    "    return float(np.max(x))\n",
    "\n",
    "def load_metrics_max_mean(root: str) -> List[Dict[str, Any]]:\n",
    "    paths = find_run_csvs(root, CSV_NAME)\n",
    "    rows = []\n",
    "    for pth in paths:\n",
    "        run = infer_run_name(pth, root)\n",
    "        try:\n",
    "            df = pd.read_csv(pth)\n",
    "        except Exception:\n",
    "            continue\n",
    "        y_mean_col = get_first_present(df, Y_MEAN_ALIASES)\n",
    "        if y_mean_col is None:\n",
    "            continue\n",
    "        mean_series = df.get(y_mean_col, pd.Series(dtype=float))\n",
    "        mean_est = mean_max(mean_series)\n",
    "        if np.isnan(mean_est):\n",
    "            continue\n",
    "        p_val, m_val = parse_p_m_from_run(run)\n",
    "        rows.append({\"run\": run, \"p\": p_val, \"m\": m_val, \"mean_max\": mean_est})\n",
    "    return rows\n",
    "\n",
    "def build_matrix(rows: List[Dict[str, Any]]) -> Tuple[np.ndarray, np.ndarray, np.ndarray, pd.DataFrame]:\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        return np.array([]), np.array([]), np.array([[]]), pd.DataFrame(columns=[\"p\",\"m\",\"mean_max\"])\n",
    "    P_vals = np.sort(df[\"p\"].dropna().unique())\n",
    "    M_vals = np.sort(df[\"m\"].dropna().unique())\n",
    "    mean_matrix = np.full((len(P_vals), len(M_vals)), np.nan, dtype=float)\n",
    "    grouped = df.groupby([\"p\", \"m\"], dropna=False).agg({\"mean_max\": \"mean\"}).reset_index()\n",
    "    p_index = {p: i for i, p in enumerate(P_vals)}\n",
    "    m_index = {m: j for j, m in enumerate(M_vals)}\n",
    "    for _, row in grouped.iterrows():\n",
    "        p, m = row[\"p\"], row[\"m\"]\n",
    "        if p in p_index and m in m_index:\n",
    "            i, j = p_index[p], m_index[m]\n",
    "            mean_matrix[i, j] = row[\"mean_max\"]\n",
    "    tidy = pd.DataFrame({\n",
    "        \"p\": np.repeat(P_vals, len(M_vals)),\n",
    "        \"m\": np.tile(M_vals, len(P_vals)),\n",
    "        \"mean_max\": mean_matrix.reshape(-1),\n",
    "    })\n",
    "    return P_vals, M_vals, mean_matrix, tidy\n",
    "\n",
    "def make_green_good_red_bad_cmap() -> LinearSegmentedColormap:\n",
    "    colors = [(0.0, \"#d73027\"), (0.5, \"#fdae61\"), (0.75, \"#a6d96a\"), (1.0, \"#1a9850\")]\n",
    "    return LinearSegmentedColormap.from_list(\"red_yellow_green\", colors)\n",
    "\n",
    "def _auto_norm(matrix: np.ndarray):\n",
    "    finite_vals = matrix[np.isfinite(matrix)]\n",
    "    if finite_vals.size == 0:\n",
    "        return 0.0, 1.0, LogNorm(vmin=1e-6, vmax=1.0)\n",
    "    vmin, vmax = np.nanmin(finite_vals), np.nanmax(finite_vals)\n",
    "    if np.isclose(vmin, vmax):\n",
    "        delta = 1.0 if vmax == 0 else abs(vmax) * 0.1\n",
    "        vmin, vmax = vmax - delta, vmax + delta\n",
    "    if np.all(finite_vals > 0):\n",
    "        eps = np.nextafter(0, 1)\n",
    "        return vmin, vmax, LogNorm(vmin=max(vmin, eps), vmax=vmax)\n",
    "    linthresh = max(1e-6, 0.01 * max(1e-9, (vmax - vmin)))\n",
    "    return vmin, vmax, SymLogNorm(linthresh=linthresh, vmin=vmin, vmax=vmax)\n",
    "\n",
    "def _imshow(ax, matrix: np.ndarray, P_vals: np.ndarray, M_vals: np.ndarray, title: str, fig: plt.Figure, cmap: LinearSegmentedColormap):\n",
    "    vmin, vmax, norm = _auto_norm(matrix)\n",
    "    im = ax.imshow(matrix, aspect=\"auto\", origin=\"lower\", cmap=cmap, norm=norm, interpolation=\"nearest\")\n",
    "    ax.set_title(title, pad=6)\n",
    "    ax.set_ylabel(\"Augmentation m\", labelpad=4)\n",
    "    ax.set_xlabel(\"Dropout p\", labelpad=4)\n",
    "    ax.set_xticks(range(len(M_vals)))\n",
    "    ax.set_yticks(range(len(P_vals)))\n",
    "    ax.set_xticklabels([f\"{m:g}\" for m in M_vals], rotation=35, ha=\"right\")\n",
    "    ax.set_yticklabels([f\"{p:g}\" for p in P_vals])\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", labelsize=8, pad=2)\n",
    "    im.cmap.set_bad(color=\"#bdbdbd\")\n",
    "    im.set_data(np.ma.masked_invalid(matrix))\n",
    "    cbar = fig.colorbar(im, ax=ax, fraction=0.035, pad=0.02)\n",
    "    cbar.ax.tick_params(labelsize=8, pad=2)\n",
    "    cbar.ax.set_ylabel(\"Max Validation Reward\", rotation=270, labelpad=10)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    ax.grid(False)\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    try:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def main():\n",
    "    rows = load_metrics_max_mean(ROOT_DIR)\n",
    "    if not rows:\n",
    "        print(f\"No valid runs found to build matrix from: {ROOT_DIR}\")\n",
    "        return\n",
    "    P_vals, M_vals, mean_matrix, tidy = build_matrix(rows)\n",
    "    try:\n",
    "        display(pd.DataFrame(rows))\n",
    "        display(tidy)\n",
    "    except NameError:\n",
    "        print(pd.DataFrame(rows).head())\n",
    "        print(tidy.head())\n",
    "    plt.rcParams.update({\n",
    "        \"figure.dpi\": 120,\n",
    "        \"savefig.dpi\": 300,\n",
    "        \"axes.titlesize\": 11,\n",
    "        \"axes.labelsize\": 9,\n",
    "        \"xtick.labelsize\": 8,\n",
    "        \"ytick.labelsize\": 8,\n",
    "        \"axes.titlepad\": 6,\n",
    "    })\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6.2, 4.6), constrained_layout=True)\n",
    "    cmap = make_green_good_red_bad_cmap()\n",
    "    _imshow(ax, mean_matrix, P_vals, M_vals, \"Max Mean Reward by Augmentation and Dropout\", fig, cmap)\n",
    "    ensure_dir(PLOTS_DIR)\n",
    "    out_path = os.path.join(PLOTS_DIR, PNG_NAME)\n",
    "    try:\n",
    "        fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "        print(f\"Saved heatmap to '{out_path}'\")\n",
    "    except Exception:\n",
    "        print(f\"Failed to save figure to '{out_path}'\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "f7c0d787c1fddc60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "ROOT_DIR = \"./outputs\"\n",
    "CSV_NAME = \"sit_format.csv\"\n",
    "PLOTS_DIR = \"./plots\"\n",
    "OUT_NAME = \"vtrace_drac_chaser_fruitbot.png\"\n",
    "Y_MEAN_ALIASES = [\"test/mean_episode_reward\", \"test/mean_reward\"]\n",
    "\n",
    "def find_run_csvs(root: str, csv_name: str) -> List[str]:\n",
    "    paths = []\n",
    "    for dirpath, _, filenames in os.walk(root):\n",
    "        if csv_name in filenames:\n",
    "            paths.append(os.path.join(dirpath, csv_name))\n",
    "    return sorted(paths)\n",
    "\n",
    "def infer_run_name(path: str, root: str) -> str:\n",
    "    rel = os.path.relpath(os.path.dirname(path), root)\n",
    "    return rel.replace(\"\\\\\", \"/\")\n",
    "\n",
    "def parse_tokens(run_name: str) -> Dict[str, Any]:\n",
    "    algo = \"vtrace\" if \"vtrace\" in run_name else None\n",
    "    drac = \"drac\" if \"drac\" in run_name else None\n",
    "    m = re.search(r\"drac[_\\-]?([0-9]*\\.?[0-9]+(?:[eE][+\\-]?\\d+)?)\", run_name)\n",
    "    drac_val = float(m.group(1)) if m else np.nan\n",
    "    env = \"fruitbot\" if \"fruitbot\" in run_name else (\"chaser\" if \"chaser\" in run_name else None)\n",
    "    return {\"algo\": algo, \"drac\": drac, \"drac_val\": drac_val, \"env\": env}\n",
    "\n",
    "def get_first_present(df: pd.DataFrame, candidates: List[str]) -> str | None:\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def mean_max(series) -> float:\n",
    "    x = pd.to_numeric(pd.Series(series), errors=\"coerce\").dropna().values\n",
    "    return float(np.max(x)) if x.size else np.nan\n",
    "\n",
    "def load_rows(root: str) -> List[Dict[str, Any]]:\n",
    "    rows = []\n",
    "    for pth in find_run_csvs(root, CSV_NAME):\n",
    "        run = infer_run_name(pth, root)\n",
    "        toks = parse_tokens(run)\n",
    "        if toks[\"algo\"] != \"vtrace\" or toks[\"drac\"] != \"drac\" or toks[\"env\"] not in (\"fruitbot\", \"chaser\"):\n",
    "            continue\n",
    "        try:\n",
    "            df = pd.read_csv(pth)\n",
    "        except Exception:\n",
    "            continue\n",
    "        ycol = get_first_present(df, Y_MEAN_ALIASES)\n",
    "        if not ycol:\n",
    "            continue\n",
    "        val = mean_max(df[ycol])\n",
    "        if np.isnan(val):\n",
    "            continue\n",
    "        rows.append({\"run\": run, \"env\": toks[\"env\"], \"drac\": toks[\"drac_val\"], \"reward\": val})\n",
    "    return rows\n",
    "\n",
    "def ensure_zero_row(df_env: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df_env.empty:\n",
    "        return df_env\n",
    "    if not np.isclose(df_env[\"drac\"].fillna(np.inf).values, 0.0).any():\n",
    "        zero_reward = np.nan\n",
    "        df_env = pd.concat([df_env, pd.DataFrame([{\"env\": df_env[\"env\"].iloc[0], \"drac\": 0.0, \"reward\": zero_reward}])], ignore_index=True)\n",
    "    return df_env\n",
    "\n",
    "def plot_side_by_side(df: pd.DataFrame, out_dir: str, out_name: str):\n",
    "    ch = df[df[\"env\"] == \"chaser\"].copy()\n",
    "    fr = df[df[\"env\"] == \"fruitbot\"].copy()\n",
    "    ch = ensure_zero_row(ch)\n",
    "    fr = ensure_zero_row(fr)\n",
    "    ch = ch.sort_values(\"drac\")\n",
    "    fr = fr.sort_values(\"drac\")\n",
    "    if ch.empty and fr.empty:\n",
    "        print(\"No DRAC runs found for chaser or fruitbot\")\n",
    "        return\n",
    "    plt.rcParams.update({\n",
    "        \"figure.dpi\": 120,\n",
    "        \"savefig.dpi\": 300,\n",
    "        \"axes.titlesize\": 11,\n",
    "        \"axes.labelsize\": 9,\n",
    "        \"xtick.labelsize\": 8,\n",
    "        \"ytick.labelsize\": 8,\n",
    "        \"axes.titlepad\": 6,\n",
    "    })\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10.0, 4.2), constrained_layout=True, sharey=False)\n",
    "\n",
    "    def _one(ax, sub, title):\n",
    "        if sub.empty:\n",
    "            ax.text(0.5, 0.5, \"No data\", ha=\"center\", va=\"center\")\n",
    "            ax.set_title(title)\n",
    "            ax.set_xlabel(\"DRAC coefficient\")\n",
    "            return\n",
    "        x = sub[\"drac\"].values\n",
    "        y = sub[\"reward\"].values\n",
    "        ax.plot(x, y, marker=\"o\", linestyle=\"-\", linewidth=1.6, markersize=4)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"DRAC coefficient\")\n",
    "        ax.set_xlim(left=0.0)\n",
    "        ax.grid(True, linestyle=\":\", linewidth=0.6, alpha=0.6)\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(False)\n",
    "\n",
    "    _one(axes[0], ch, \"V-trace DRAC Performance (chaser)\")\n",
    "    _one(axes[1], fr, \"V-trace DRAC Performance (fruitbot)\")\n",
    "    axes[0].set_ylabel(\"Max Mean Reward\")\n",
    "    axes[1].set_ylabel(\"Max Mean Reward\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, out_name)\n",
    "    fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "    print(f\"Saved side-by-side plot to '{out_path}'\")\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    rows = load_rows(ROOT_DIR)\n",
    "    if not rows:\n",
    "        print(\"No DRAC runs found\")\n",
    "        return\n",
    "    df = pd.DataFrame(rows)\n",
    "    plot_side_by_side(df, PLOTS_DIR, OUT_NAME)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "8db30e10744e3d19"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
